{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4fa73e",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>Interpretability</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2646d3e",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "This notebook explores interpretability of machine learning models using white box (ridge regression) and black box (random forest regression) approaches on the diabetes dataset. It showcases local and global interpretability techniques, including feature importance analysis and SHAP values, highlighting instances where the black box model outperforms the white box model in prediction accuracy.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09b82b",
   "metadata": {},
   "source": [
    "## Generals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36820108",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Packages import and system configurations. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from ipywidgets import interactive\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e32451",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>Main Functionality</center>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd51ac",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd16a1",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Split features and target.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_x_y(df):\n",
    "    x = df.data\n",
    "    y = df.target\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a308711d",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Split train-test sets.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f168d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(df):\n",
    "    x, y = splits_x_y(df)\n",
    "    return train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc78ad",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Scalling.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd408014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaller(train,test):\n",
    "    StandardScaler = preprocessing.MinMaxScaler()\n",
    "    scalled_train_data = StandardScaler.fit_transform(train)\n",
    "    scalled_test_data = StandardScaler.transform(test)\n",
    "    return scalled_train_data, scalled_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034200d",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Data preprocesssing pipeline.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_pipeline():\n",
    "    diabetes = datasets.load_diabetes()\n",
    "    feature_names = diabetes['feature_names']\n",
    "    x_train, x_test, y_train, y_test =  split_test_train(diabetes)\n",
    "    x_train, x_test = scaller(x_train, x_test)       \n",
    "    return x_train, x_test, y_train, y_test, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c562950c",
   "metadata": {},
   "source": [
    "## Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06554463",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the function bellow is to train a white box model and evaluate its performance.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Fit the model using the training data.</li>\n",
    "<li>Predict the target values for both the training and test data.</li>\n",
    "<li>Print the mean absolute error (MAE) performance metrics for the training and test sets.</li>\n",
    "<li>Return the trained model and the predicted test values.</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_white_box_model(model,x_train,x_test,y_train,y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    predicted_train = model.predict(x_train)\n",
    "    predicted_test = model.predict(x_test)\n",
    "    print(\"Ridge Regression Model Performance:\")\n",
    "    print(\"MAE in Train Set\", round(mean_absolute_error(y_train, predicted_train), 3))\n",
    "    print(\"MAE in Test Set\", round(mean_absolute_error(y_test, predicted_test), 3))\n",
    "    return model, predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e5d84",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the function bellow is to train a black box model (Random Forest Regression) with optimal hyperparameters and evaluate its performance.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Perform a grid search using cross-validation to find the best hyperparameters based on negative mean squared error scoring.</li>\n",
    "<li>Fit the optimal model to the training data and predict the target values for both the training and test data.</li>\n",
    "<li>Print the mean absolute error (MAE) performance metrics for the training and test sets.</li>\n",
    "<li>Return the trained model and the predicted test values.</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b31f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_black_box_model(param_grid, x_train, x_test, y_train, y_test):\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print(\"RandomForestRegressor Best Hyperparameters:\", grid_search.best_params_)\n",
    "    \n",
    "    optimal_model = RandomForestRegressor(**grid_search.best_params_)\n",
    "    model.fit(x_train, y_train)\n",
    "    predicted_train = model.predict(x_train)\n",
    "    predicted_test = model.predict(x_test)\n",
    "    print(\"RandomForest Regression Model Performance:\")\n",
    "    print(\"MAE in Train Set\", round(mean_absolute_error(y_train, predicted_train), 3))\n",
    "    print(\"MAE in Test Set\", round(mean_absolute_error(y_test, predicted_test), 3))\n",
    "    return model, predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04698a",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585183f3",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the function bellow is to perform global interpretation of a white box model (Ridge Regression) by analyzing the feature weights.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Extract the feature weights from the linear regression model.</li>\n",
    "<li>Remove rows where weights are zero.</li>\n",
    "<li>Print the number of features included in the interpretation.</li>\n",
    "<li>Display a bar plot of feature weights.</li>\n",
    "<li>Print the intercept (bias) value of the linear model.</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_interpretation_white_box(lin_model, feature_names):\n",
    "    weights = lin_model.coef_\n",
    "    model_weights = pd.DataFrame({'features': list(feature_names), 'weights': list(weights)})\n",
    "    model_weights = model_weights.reindex(model_weights['weights'].abs().sort_values(ascending=False).index) # Sort by absolute value\n",
    "    model_weights = model_weights[(model_weights[\"weights\"] != 0)]\n",
    "    print(\"Number of features:\", len(model_weights.values))\n",
    "    print(\"\\nModel Weights : \\n\", model_weights)\n",
    "    plt.figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "    sns.barplot(x=\"weights\", y=\"features\", data=model_weights)\n",
    "    plt.title(\"Intercept (Bias): \" + str(lin_model.intercept_), loc='right')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    return model_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b3401",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the function bellow is to perform global interpretation of a black box model (Random Forest Regression) using SHAP values.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Initialize a SHAP TreeExplainer object with the black box model and feature names.</li>\n",
    "<li>Compute the SHAP values for the test data.</li>\n",
    "<li>Print the feature weights (SHAP values).</li>\n",
    "<li>Return the DataFrame, SHAP library, explainer object, and SHAP values.</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0449b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_interpretation_black_box(model, x_test, feature_names):\n",
    "    explainer = shap.TreeExplainer(model, feature_names=list(feature_names))\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "    # Reshape the SHAP values to match the expected shape\n",
    "    reshape_shap_values = shap_values[0].reshape(-1)\n",
    "    # Create a DataFrame with feature names and corresponding SHAP values\n",
    "    shap_df = pd.DataFrame({'Feature': feature_names, 'SHAP Value': reshape_shap_values})\n",
    "    shap_df = shap_df.sort_values(by='SHAP Value', key=lambda x: abs(x), ascending=False)\n",
    "    # Print the feature weights\n",
    "    print(\"Feature Weights:\\n\",shap_df)\n",
    "    return shap_df, shap, explainer, shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842979c7",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the function bellow is to use the test-set in order to perform local interpretation of a white box model (Linear Regression) for a specific instance.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Retrieve the random instance from the test data.</li>\n",
    "<li>Compute the weighted sum of features for the instance using the model's coefficients.</li>\n",
    "<li>Compute the overall result by adding the weighted sum to the model's intercept (bias).</li>\n",
    "<li>Print the number of features considered.</li>\n",
    "<li>Visualize the feature weights using a bar plot.</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_interpretation_white_box(lin_model, x_test, y_test, predicted_test, instance, feature_names):\n",
    "    random_instance = x_test[instance]\n",
    "    print(\"Original Value:\", y_test[instance], \", Predicted Value:\", round(predicted_test[instance],2))\n",
    "    weights = lin_model.coef_\n",
    "    summation = sum(weights[0] * random_instance)\n",
    "    bias = lin_model.intercept_\n",
    "    result = summation + bias\n",
    "    print(\"Sum(weights * instance):\", round(summation,2), \"+ Intercept (Bias):\", round(bias,2), \"=\", round(result,2))\n",
    "    \n",
    "    model_weights = pd.DataFrame({'features': list(feature_names), 'weights*values': list(weights[0] * random_instance)})\n",
    "    model_weights = model_weights.reindex(model_weights['weights*values'].abs().sort_values(ascending=False).index) # Sort by absolute value\n",
    "    model_weights = model_weights[(model_weights[\"weights*values\"] != 0)]    \n",
    "    print(\"Number of features:\", len(model_weights.values))\n",
    "    print(\"\\nModel Weights : \\n\", model_weights)\n",
    "    plt.figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "    sns.barplot(x=\"weights*values\", y=\"features\", data=model_weights)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    return model_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb7bd8",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The aim of the function bellow is to use the test-set in order to perform local interpretation of a black box model (Random Forest Regression) for a specific instance.\n",
    "<br>\n",
    "<br>\n",
    "The function performs the following steps:\n",
    "<ol>\n",
    "<li>Create a SHAP TreeExplainer object for the given model and feature names.</li>\n",
    "<li>Compute the SHAP values for the specified instance using the explainer.</li>\n",
    "<li>Print the feature weights (SHAP values).</li>\n",
    "<li>Return the DataFrame of feature weights, along with the SHAP objects (explainer and SHAP values).</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20fa493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_interpretation_black_box(model, x_test, instance, feature_names):\n",
    "    explainer = shap.TreeExplainer(model, feature_names=list(feature_names))\n",
    "    shap_values = explainer.shap_values(x_test[instance:instance+1])\n",
    "    # Reshape the SHAP values to match the expected shape\n",
    "    reshape_shap_values = shap_values[0].reshape(-1)\n",
    "    # Create a DataFrame with feature names and corresponding SHAP values\n",
    "    shap_df = pd.DataFrame({'Feature': feature_names, 'SHAP Value': reshape_shap_values})\n",
    "    shap_df = shap_df.sort_values(by='SHAP Value', key=lambda x: abs(x), ascending=False)\n",
    "    # Print the feature weights\n",
    "    print(\"Feature Weights:\\n\",shap_df)\n",
    "    return shap_df, shap, explainer, shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e65af0",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>Pipeline Execution</center>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8d40e",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Global Envariables.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d602dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {'n_estimators': [200, 220, 250], 'max_depth': [1, 5, 10], 'min_samples_split': [2, 5, 10]}\n",
    "white_box_model = Ridge(solver ='sag', tol = 2, random_state=42)\n",
    "instance = 10\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6caea",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, feature_names = get_data_pipeline()\n",
    "print('Train and Evalaute white-box model!')\n",
    "white_box_model, white_box_predicted_test = train_white_box_model(white_box_model,x_train,x_test,y_train,y_test)\n",
    "print('\\nTrain and Evalaute black-box model!')\n",
    "black_box_model, black_box_predicted_test = train_black_box_model(rf_param_grid,x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03a209",
   "metadata": {},
   "source": [
    "### Global Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92775b65",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "White-box Model (Ridge Regression)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d4143",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('White box global weights!')\n",
    "white_box_global_weights = global_interpretation_white_box(white_box_model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32538b4a",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Black-box Model (Random Forest)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53da504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Black box global weights!')\n",
    "shap_global_df,shap_global,explainer_global,shap_values_global = global_interpretation_black_box(black_box_model, \n",
    "                                                           x_test, feature_names)\n",
    "shap_global.summary_plot(shap_values_global, x_test, feature_names=list(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f87bd4",
   "metadata": {},
   "source": [
    "### Local Interpretability (test sample 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78522a88",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "White-box Model (Ridge Regression)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099011f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('White box local weights!')\n",
    "white_box_local_weights = local_interpretation_white_box(white_box_model,x_test,y_test,white_box_predicted_test,instance,feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca247f61",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Black-box Model (Random Forest)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d37bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Black box local weights!')\n",
    "shap_local_df,shap_local,explainer_local,shap_values_local = local_interpretation_black_box(black_box_model, \n",
    "                                                           x_test, instance, feature_names)\n",
    "shap_local.force_plot(explainer_local.expected_value, shap_values_local[0], \n",
    "                      x_test[instance:instance+1], feature_names=list(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b6a03",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>Interpretability Analysis and Performance Comparison</center>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b24af",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "<b>Performance Comparison:</b>\n",
    "The performance of the models is compared based on Mean Absolute Error (MAE). The white-box model (Ridge Regression) achieves an MAE of <b>48.424</b> on the test set, while the black-box model (Random Forest Regression) performs better with an MAE of <b>43.752</b>. The black-box model outperforms the white-box model, achieving lower MAE values in both sets.\n",
    "\n",
    "<b>Global Interpretability:</b>\n",
    "For global interpretability, the feature weights are examined. Surprisingly, both models highlight the same top two important features, namely BMI and s5. However, the white-box model assigns higher weights to these features, indicating their stronger influence on predictions.\n",
    "\n",
    "<b>Local Interpretability:</b>\n",
    "Analyzing the feature weights for specific instances at the local level, the white-box model consistently assigns higher weights to features s1, s3, and s2 across multiple instances. For example, in one instance with an original value of 94.0 and a predicted value of 133.89, the weights of s1, s3, and s2 contribute significantly to the prediction with values of 6.62, 6.25, and 5.59, respectively. In contrast, the black-box model exhibits more varied feature importance across instances, with varying weights for features such as BMI, s5, and s3.\n",
    "\n",
    "<b>Comparison of Interpretability:</b>\n",
    "The comparison of interpretability between the models reveals interesting nuances. While they share common important features at the global level, the white-box model provides more consistent and predictable feature importance at the local level, whereas the black-box model exhibits greater variability.\n",
    "\n",
    "<b>Conclusion:</b>\n",
    "The analysis underscores the trade-off between interpretability and performance. Although the black-box model outperforms the white-box model in terms of predictive accuracy, the white-box model offers more consistent interpretability both globally and locally. Understanding this trade-off is crucial for choosing the appropriate model based on the specific requirements of the task at hand.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a36dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
